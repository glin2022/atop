{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch, time, torchattacks, random, argparse\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from models.resnet import ResNet18, ResNet34, ResNet50\n",
    "from model.networks import Generator, Discriminator\n",
    "import utils.misc as misc\n",
    "import model.losses as gan_losses\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "from util import get_mask_list\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(777)\n",
    "image_nc = 3\n",
    "batch_size = 8\n",
    "epochs = 300\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', type=str,\n",
    "                    default=\"configs/train.yaml\", help=\"Path to yaml config file\")\n",
    "args = parser.parse_args(args=['--config', 'configs/train.yaml'])\n",
    "config = misc.get_config(args.config)\n",
    "\n",
    "checkpoint_dir = 'checkpoint/cifar_tmp'\n",
    "config.checkpoint_dir = checkpoint_dir\n",
    "config.batch_size = batch_size\n",
    "tmp_n = 10\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "     transforms.Resize(256),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "     transforms.Resize(256),\n",
    "     transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_set = datasets.CIFAR10(\"./data\", download=True, transform=transform_train)\n",
    "test_set = datasets.CIFAR10(\"./data\", download=True, transform=transform_test, train=False)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "discriminator = Discriminator(cnum_in=4, cnum=64)\n",
    "\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "class Model_g(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_g, self).__init__()\n",
    "\n",
    "        sd_path = 'pretrained/states_pt_places2.pth'\n",
    "        self.generator = Generator(cnum_in=5, cnum=48, return_flow=False, checkpoint=sd_path)\n",
    "        self.generator.train()\n",
    "\n",
    "        self.res = ResNet18()\n",
    "        self.res.load_state_dict(torch.load('./models/state_dicts/resnet18_cifar10.pth'))\n",
    "        self.res.eval()\n",
    "\n",
    "    def forward(self, x, adv_x, mask, test_flag):\n",
    "        x1, x2 = self.generator(x, mask)\n",
    "        if not test_flag:\n",
    "            adv_x1, adv_x2 = self.generator(adv_x, mask)\n",
    "            outputs_cls = self.res(adv_x2)\n",
    "        else: outputs_cls = self.res(x2)\n",
    "\n",
    "        batch_complete = x2\n",
    "        return x1, x2, batch_complete, outputs_cls\n",
    "\n",
    "model = Model_g().to(device)\n",
    "for param in model.named_parameters():\n",
    "    if 'res' in param[0]:\n",
    "        param[1].requires_grad = False\n",
    "\n",
    "model_res = ResNet18().to(device)\n",
    "model_res.load_state_dict(torch.load('./models/state_dicts/resnet18_cifar10.pth'))\n",
    "model_res.eval()\n",
    "\n",
    "g_optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=config.g_lr, betas=(config.g_beta1, config.g_beta2))\n",
    "d_optimizer = torch.optim.Adam(\n",
    "    discriminator.parameters(), lr=config.d_lr, betas=(config.d_beta1, config.d_beta2))\n",
    "\n",
    "gan_loss_d, gan_loss_g = gan_losses.hinge_loss_d, gan_losses.hinge_loss_g\n",
    "loss_fun = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "if config.tb_logging:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter(config.log_dir)\n",
    "\n",
    "losses = {}\n",
    "\n",
    "discriminator.train()\n",
    "\n",
    "last_n_iter = -1\n",
    "losses_log = {'d_loss':   [],\n",
    "              'g_loss':   [],\n",
    "              'ae_loss':  [],\n",
    "              'ae_loss1': [],\n",
    "              'ae_loss2': [],\n",
    "              'cls_loss': [],\n",
    "              }\n",
    "\n",
    "# training loop\n",
    "init_n_iter = last_n_iter + 1\n",
    "n_iter = 0\n",
    "time0 = time.time()\n",
    "\n",
    "block_n = 32\n",
    "gau_n = 0.25\n",
    "missing_rate = 0.25\n",
    "cls_n = 0.05\n",
    "atk1 = torchattacks.FGSM(model_res, eps=8/255.)\n",
    "atk2 = torchattacks.BIM(model_res, eps=8/255.)\n",
    "atk3 = torchattacks.EOTPGD(model_res, eps=8/255.)\n",
    "atk4 = torchattacks.PGD(model_res, eps=8/255., steps=20)\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_acc = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        batch_real, labels = data\n",
    "        batch_real, labels = batch_real.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        batch_adv = atk1(batch_real, labels)\n",
    "        batch_real = batch_adv.clone().detach()\n",
    "\n",
    "        gau_noise = torch.normal(0, 1, batch_real.shape)*gau_n\n",
    "        gau_noise = gau_noise.to(device)\n",
    "        batch_gau = torch.clip((batch_real+gau_noise), 0, 1)\n",
    "        adv_gau = torch.clip((batch_adv+gau_noise), 0, 1)\n",
    "        batch_gau.mul_(2).sub_(1)\n",
    "\n",
    "        adv_gau.mul_(2).sub_(1)\n",
    "        batch_real.mul_(2).sub_(1)\n",
    "\n",
    "        nums = np.zeros(int((256**2) / (block_n**2)))\n",
    "        nums[:int(missing_rate*(len(nums)))] = 1\n",
    "        np.random.shuffle(nums)\n",
    "        mask = nums.reshape((1,1,int(256/block_n),int(256/block_n)))\n",
    "\n",
    "\n",
    "        mask = np.repeat(mask, block_n, axis=2)\n",
    "        mask = np.repeat(mask, block_n, axis=3)\n",
    "\n",
    "        mask = torch.from_numpy(mask).type(torch.float).to(device)\n",
    "\n",
    "        batch_incomplete = batch_gau*(1.-mask)\n",
    "        ones_x = torch.ones_like(batch_incomplete)[:, 0:1, :, :].to(device)\n",
    "        x = torch.cat([batch_incomplete, ones_x, ones_x*mask], axis=1)\n",
    "\n",
    "        adv_incomplete = adv_gau*(1.-mask)\n",
    "        adv_ones_x = torch.ones_like(adv_incomplete)[:, 0:1, :, :].to(device)\n",
    "        adv_x = torch.cat([adv_incomplete, adv_ones_x, adv_ones_x*mask], axis=1)\n",
    "\n",
    "        x1, x2, batch_complete, outputs_cls = model(x, adv_x, mask, False)\n",
    "        batch_predicted = x2.clone().detach()\n",
    "        batch_complete = x2.clone().detach()\n",
    "\n",
    "        loss_cls = loss_fun(outputs_cls, labels)\n",
    "\n",
    "        losses['cls_loss'] = loss_cls\n",
    "\n",
    "        batch_real_mask = torch.cat(\n",
    "            (batch_real, torch.tile(mask, [config.batch_size, 1, 1, 1])), dim=1)\n",
    "        batch_filled_mask = torch.cat((batch_complete.detach(), torch.tile(\n",
    "            mask, [config.batch_size, 1, 1, 1])), dim=1)\n",
    "\n",
    "        batch_real_filled = torch.cat((batch_real_mask, batch_filled_mask))\n",
    "\n",
    "        d_real_gen = discriminator(batch_real_filled)\n",
    "        d_real, d_gen = torch.split(d_real_gen, config.batch_size)\n",
    "\n",
    "        d_loss = gan_loss_d(d_real, d_gen)\n",
    "        losses['d_loss'] = d_loss\n",
    "\n",
    "        # update D parameters\n",
    "        d_optimizer.zero_grad()\n",
    "        losses['d_loss'].backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        losses['ae_loss1'] = config.l1_loss_alpha * \\\n",
    "            torch.mean((torch.abs(batch_real - x1)))\n",
    "        losses['ae_loss2'] = config.l1_loss_alpha * \\\n",
    "            torch.mean((torch.abs(batch_real - x2)))\n",
    "        losses['ae_loss'] = losses['ae_loss1'] + losses['ae_loss2']\n",
    "\n",
    "        batch_gen = batch_predicted\n",
    "        batch_gen = torch.cat((batch_gen, torch.tile(\n",
    "            mask, [config.batch_size, 1, 1, 1])), dim=1)\n",
    "\n",
    "        d_gen = discriminator(batch_gen)\n",
    "\n",
    "        g_loss = gan_loss_g(d_gen)\n",
    "        losses['g_loss'] = g_loss\n",
    "        losses['g_loss'] = config.gan_loss_alpha * losses['g_loss']\n",
    "        if config.ae_loss:\n",
    "            losses['g_loss'] += losses['ae_loss']\n",
    "            if epoch > 2: losses['g_loss'] += losses['cls_loss']*cls_n\n",
    "\n",
    "        # update G parameters\n",
    "        g_optimizer.zero_grad()\n",
    "        losses['g_loss'].backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # LOGGING\n",
    "        for k in losses_log.keys():\n",
    "            losses_log[k].append(losses[k].item())\n",
    "\n",
    "        # (tensorboard) logging\n",
    "        if n_iter % config.print_iter == 0:\n",
    "            # measure iterations/second\n",
    "            dt = time.time() - time0\n",
    "            print(f\"@iter: {n_iter}: {(config.print_iter/dt):.4f} it/s\")\n",
    "            time0 = time.time()\n",
    "\n",
    "            # write loss terms to console\n",
    "            # and tensorboard\n",
    "            for k, loss_log in losses_log.items():\n",
    "                loss_log_mean = sum(loss_log)/len(loss_log)\n",
    "                print(f\"{k}: {loss_log_mean:.4f}\")\n",
    "                if config.tb_logging:\n",
    "                    writer.add_scalar(\n",
    "                        f\"losses/{k}\", loss_log_mean, global_step=n_iter)\n",
    "                losses_log[k].clear()\n",
    "\n",
    "        # save example image grids to tensorboard\n",
    "        if config.tb_logging \\\n",
    "            and config.save_imgs_to_tb_iter \\\n",
    "            and n_iter % config.save_imgs_to_tb_iter == 0:\n",
    "            viz_images = [misc.pt_to_image(batch_complete),\n",
    "                          misc.pt_to_image(x1), misc.pt_to_image(x2)]\n",
    "            img_grids = [tv.utils.make_grid(images[:config.viz_max_out], nrow=2)\n",
    "                        for images in viz_images]\n",
    "\n",
    "            writer.add_image(\n",
    "                \"Inpainted\", img_grids[0], global_step=n_iter, dataformats=\"CHW\")\n",
    "            writer.add_image(\n",
    "                \"Stage 1\", img_grids[1], global_step=n_iter, dataformats=\"CHW\")\n",
    "            writer.add_image(\n",
    "                \"Stage 2\", img_grids[2], global_step=n_iter, dataformats=\"CHW\")\n",
    "\n",
    "        # save example image grids to disk\n",
    "        if config.save_imgs_to_disc_iter \\\n",
    "            and n_iter % config.save_imgs_to_disc_iter == 0:\n",
    "            viz_images = [misc.pt_to_image(batch_real),\n",
    "                          misc.pt_to_image(batch_complete)]\n",
    "            img_grids = [tv.utils.make_grid(images[:config.viz_max_out], nrow=2)\n",
    "                                            for images in viz_images]\n",
    "            tv.utils.save_image(img_grids,\n",
    "            f\"{checkpoint_dir}/iter_{tmp_n}_{n_iter}.png\",\n",
    "            nrow=2)\n",
    "\n",
    "        # save state dict snapshot\n",
    "        if n_iter % config.save_checkpoint_iter == 0 \\\n",
    "            and n_iter > init_n_iter:\n",
    "            misc.save_states(f\"states_{tmp_n}.pth\",\n",
    "                        model, discriminator,\n",
    "                        g_optimizer, d_optimizer,\n",
    "                        n_iter, config)\n",
    "        # save state dict snapshot backup\n",
    "        if config.save_cp_backup_iter \\\n",
    "            and n_iter % config.save_cp_backup_iter == 0 \\\n",
    "            and n_iter > init_n_iter:\n",
    "            misc.save_states(f\"states_{tmp_n}_{n_iter}.pth\",\n",
    "                        model, discriminator,\n",
    "                        g_optimizer, d_optimizer,\n",
    "                        n_iter, config)\n",
    "        n_iter += 1\n",
    "        if i==624: break\n",
    "\n",
    "    acc=0\n",
    "    acc_atk1=0\n",
    "    acc_atk2=0\n",
    "    acc_atk3=0\n",
    "    acc_atk4=0\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        adv_inputs1 = atk1(inputs, labels)\n",
    "        adv_inputs2 = atk2(inputs, labels)\n",
    "        adv_inputs3 = atk3(inputs, labels)\n",
    "        adv_inputs4 = atk4(inputs, labels)\n",
    "\n",
    "        gau_noise = torch.normal(0, 1, inputs.shape)*gau_n\n",
    "        gau_noise = gau_noise.to(device)\n",
    "\n",
    "        inputs_gau = torch.clip((inputs+gau_noise), 0, 1)\n",
    "        adv_gau1 = torch.clip((adv_inputs1+gau_noise), 0, 1)\n",
    "        adv_gau2 = torch.clip((adv_inputs2+gau_noise), 0, 1)\n",
    "        adv_gau3 = torch.clip((adv_inputs3+gau_noise), 0, 1)\n",
    "        adv_gau4 = torch.clip((adv_inputs4+gau_noise), 0, 1)\n",
    "\n",
    "\n",
    "        inputs_gau.mul_(2).sub_(1)\n",
    "        adv_gau1.mul_(2).sub_(1)\n",
    "        adv_gau2.mul_(2).sub_(1)\n",
    "        adv_gau3.mul_(2).sub_(1)\n",
    "        adv_gau4.mul_(2).sub_(1)\n",
    "\n",
    "        nums = np.zeros(int((256**2) / (block_n**2)))\n",
    "        nums[:int(missing_rate*(len(nums)))] = 1\n",
    "        np.random.shuffle(nums)\n",
    "        mask = nums.reshape((1,1,int(256/block_n),int(256/block_n)))\n",
    "\n",
    "        mask = np.repeat(mask, block_n, axis=2)\n",
    "        mask = np.repeat(mask, block_n, axis=3)\n",
    "\n",
    "        mask = torch.from_numpy(mask).type(torch.float).to(device)\n",
    "\n",
    "        batch_incomplete = inputs_gau*(1.-mask)\n",
    "        ones_x = torch.ones_like(batch_incomplete)[:, 0:1, :, :].to(device)\n",
    "        x = torch.cat([batch_incomplete, ones_x, ones_x*mask], axis=1)\n",
    "        x1, x2, batch_complete, outputs_cls = model(x, x, mask, True)\n",
    "        inputs_predicted = x2.clone().detach()\n",
    "\n",
    "        batch_incomplete = adv_gau1*(1.-mask)\n",
    "        ones_x = torch.ones_like(batch_incomplete)[:, 0:1, :, :].to(device)\n",
    "        x = torch.cat([batch_incomplete, ones_x, ones_x*mask], axis=1)\n",
    "        x1, x2, batch_complete, outputs_cls = model(x, x, mask, True)\n",
    "        adv_predicted1 = x2.clone().detach()\n",
    "\n",
    "        batch_incomplete = adv_gau2*(1.-mask)\n",
    "        ones_x = torch.ones_like(batch_incomplete)[:, 0:1, :, :].to(device)\n",
    "        x = torch.cat([batch_incomplete, ones_x, ones_x*mask], axis=1)\n",
    "        x1, x2, batch_complete, outputs_cls = model(x, x, mask, True)\n",
    "        adv_predicted2 = x2.clone().detach()\n",
    "\n",
    "        batch_incomplete = adv_gau3*(1.-mask)\n",
    "        ones_x = torch.ones_like(batch_incomplete)[:, 0:1, :, :].to(device)\n",
    "        x = torch.cat([batch_incomplete, ones_x, ones_x*mask], axis=1)\n",
    "        x1, x2, batch_complete, outputs_cls = model(x, x, mask, True)\n",
    "        adv_predicted3 = x2.clone().detach()\n",
    "\n",
    "        batch_incomplete = adv_gau4*(1.-mask)\n",
    "        ones_x = torch.ones_like(batch_incomplete)[:, 0:1, :, :].to(device)\n",
    "        x = torch.cat([batch_incomplete, ones_x, ones_x*mask], axis=1)\n",
    "        x1, x2, batch_complete, outputs_cls = model(x, x, mask, True)\n",
    "        adv_predicted4 = x2.clone().detach()\n",
    "\n",
    "\n",
    "        _, preds = torch.max(model_res(inputs_predicted), 1)\n",
    "        _, preds_atk1 = torch.max(model_res(adv_predicted1), 1)\n",
    "        _, preds_atk2 = torch.max(model_res(adv_predicted2), 1)\n",
    "        _, preds_atk3 = torch.max(model_res(adv_predicted3), 1)\n",
    "        _, preds_atk4 = torch.max(model_res(adv_predicted4), 1)\n",
    "\n",
    "        acc += torch.sum(preds == labels).item()\n",
    "        acc_atk1 += torch.sum(preds_atk1 == labels).item()\n",
    "        acc_atk2 += torch.sum(preds_atk2 == labels).item()\n",
    "        acc_atk3 += torch.sum(preds_atk3 == labels).item()\n",
    "        acc_atk4 += torch.sum(preds_atk4 == labels).item()\n",
    "        if i == 63: break\n",
    "\n",
    "    print(\"test acc on clean examples (%): {:.2f}\".format(\n",
    "            (acc / 512.) * 100.0))\n",
    "    print(\"test acc on FGSM examples (%):  {:.2f}\".format(\n",
    "            (acc_atk1 / 512.) * 100.0))\n",
    "    print(\"test acc on BIM examples (%):   {:.2f}\".format(\n",
    "            (acc_atk2 / 512.) * 100.0))\n",
    "    print(\"test acc on EoT examples (%):   {:.2f}\".format(\n",
    "            (acc_atk3 / 512.) * 100.0))\n",
    "    print(\"test acc on PGD examples (%):  {:.2f}\".format(\n",
    "            (acc_atk4 / 512.) * 100.0))\n",
    "    print('________epoch '+str(epoch)+'________')\n",
    "    misc.save_states(f\"states_{tmp_n}_{epoch}.pth\",\n",
    "                    model, discriminator,\n",
    "                    g_optimizer, d_optimizer,\n",
    "                    epoch, config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_101",
   "language": "python",
   "name": "py38_101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
